---
title: "Homework 6"
subtitle: "BIOS 684"
author: "Jeff Oliver"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
  latex_engine: xelatex
---

```{r setup, include=FALSE, fig.height = 4}
knitr::opts_chunk$set(echo = FALSE, dev = "pdf")
library("tidyr")
library("dplyr")
library("ggplot2")
library("nlme")
```

***
<!--
Study of weights of pigs:
The dataset (on the class web page) called pigweight.txt includes data on the bodyweights
of 16 pigs measured in nine successive weeks (so spanning an eight week period between
the first and last measurement). Each row of the dataset includes a pig ID number and
then the nine successive weights. [The data are from the book by Diggle et al., 2002].
-->

```{r}
pig.data <- read.delim(file = "data/pigweight.txt", header = FALSE, sep = " ")
colnames(pig.data) <- c("ID", paste0("week.", c(0:8)))
pig.data$ID <- factor(pig.data$ID)

long.data <- gather(data = pig.data, key = "week.cat", value = "weight", -ID)
long.data$week <- as.integer(substr(x = long.data$week.cat, start = 6, stop = 6))
```

### 1. Descriptive Analysis
### Create two plots, one showing the trajectories of each pigâ€™s weight over time and the other showing the trajectory of the mean weight over time. Comment on the notable features in these plots.

```{r}
# Plot individual trajectories
subject.trajectories <- ggplot(data = long.data, mapping = aes(x = week, y = weight, group = ID)) +
  geom_line() +
  ylab(label = "Weight") +
  xlab(label = "Week") +
  ggtitle(label = "Individual weight trajectories over time")
subject.trajectories

# Calculate means & standard errors for each week
mean.weights <- long.data %>%
  group_by(week) %>%
  summarise(mean.weight = mean(weight),
            se.weight = sd(weight)/sqrt(nrow(pig.data)))
# Plot mean trajectory
mean.trajectories <- ggplot(data = mean.weights, mapping = aes(x = week, y = mean.weight)) +
  geom_errorbar(data = mean.weights, mapping = aes(x = week, ymin = (mean.weight - se.weight), ymax = (mean.weight + se.weight), width = 0.15)) +
  geom_line() +
  ylab(label = "Weight") +
  xlab(label = "Week") +
  ggtitle(label = "Population mean weights over time")
mean.trajectories
```

Observations: All subjects have increasing weight through time, and the relationship appears linear for the time studied. There might be subject-specific intercepts and slopes, though; subjects that had low weight at baseline had potentially lower growth rates than did subjects with higher baseline weights. This potential difference in slopes may be contributing to increasing between-subject variance over time (heterogeneous variance).

### 2. Obtaining and Interpreting a Linear Mixed Effects Model for Bodyweight. Using PROC MIXED, fit a model for weight over (continuous) time which includes subject-specific intercepts and slopes as random effects.

The model is:

$$
Y_{ij} = \beta_{1} + \beta_{2}Week + b_{1i} + b_{2i}Week + \varepsilon_{ij}
$$
Where:

+ $\beta_{1}$: the mean intercept across subjects
+ $\beta_{2}$: the mean slope across subjects
+ $b_{1i}$: random (subject-specific) intercept
+ $b_{2i}$: random (subject-specific) slope

```{r}
# lme model with random intercept and slope
weight.model <- lme(weight ~ week,
                    random = ~1 + week | ID,
                    data = long.data)
weight.summary <- summary(weight.model)
```

#### a. Obtain and interpret parameter estimates and associated 95% confidence intervals for the fixed effects in the model for the mean trajectory.

To obtain the 95% confidence intervals, I used: $95\% C.I. = \hat{\beta} \pm 1.96 \times SE$.

```{r}
# Retrieve estimates and standard errors for fixed effects
betas <- data.frame(estimate = weight.summary$tTable[, 1], se = weight.summary$tTable[, 2])

# Calculate 95% C.I.
ci <- matrix(nrow = 2, ncol = 2)
ci[1, ] <- c(betas[1, 1] + c(-1, 1) * 1.96 * betas[1, 2])
ci[2, ] <- c(betas[2, 1] + c(-1, 1) * 1.96 * betas[2, 2])

betas <- round(betas, 2)
ci <- round(ci, 2)
```

| Coefficient | Estimate (CI)     | Interpretation                                                  |
|:-----------:|:-----------------:|:----------------------------------------------------------------|
| $\beta_{1}$ | `r betas[1, 1]` (`r ci[1, 1]`, `r ci[1, 2]`)| The population-averaged weight at baseline is `r betas[1, 1]`; the 95% C.I. excludes zero, so it is unlikely the true population-averaged weight at baseline is zero. |
| $\beta_{2}$ | `r betas[2, 1]` (`r ci[2, 1]`, `r ci[2, 2]`)| The population-averaged effect of time on weight is `r betas[2, 1]`; on average, weight increases by `r betas[2, 1]` every week. Exclusion of zero from the confidence interval indicates a significant effect of time on weight. |

#### b. Obtain and interpret parameter estimates for the variances and correlation in the model.

$Var(\beta_{1}) =$ `r round(weight.summary$varFix[1, 1], 2)`  
$Var(\beta_{2}) =$ `r round(weight.summary$varFix[2, 2], 2)`  
$Corr(\beta_{1}, \beta_{2}) =$ `r round(weight.summary$corFixed[1, 2], 2)`  

$Var(\beta_{1})$ and $Var(\beta_{2})$ show relatively low variance in population-averages estimates of weight at baseline and the change in weight over time. The correlation, $Corr(\beta_{1}, \beta_{2})$, is negative, indicating that, on average, higher weight at baseline leads to lower weight gain through time.

#### c. Obtain and interpret the 90% normal range for trends over time in body weight among pigs in the population sampled (i.e. for the pig-specific random effects for trend over time).
```{r}
# Get random effects variance covariance matrix
random.cov <- getVarCov(obj = weight.model)

# Calculate standard deviation for random time effect
time.sd <- sqrt(random.cov[2, 2])

# Calculate 5% and 95% values from normal distribution
range <- qnorm(p = c(0.05, 0.95), mean = 0, sd = time.sd)
range <- round(range, 3)
```

Assume $b_{2} \sim N(0, \sigma^2_{b})$, where $\sigma^2_{b}$ is element $g_{22}$ in the G covariance matrix. In this example, $\sigma^2_{b} = g_{22} =$ `r round(random.cov[2, 2], 2)`. Using $N(0, `r round(random.cov[2, 2], 2)`)$, the 90% range of time effects among subjects is `r range[1]` to `r range[2]`. That is, 90% of the subjects should have a subject-specific per-week change in weight between `r range[1]` and `r range[2]` in addition to the population-average change in weight over time.

### 3. The investigator who provided the data is interested in designing a randomized clinical trial to evaluate an additive to the standard pig feed which might increase the rate of growth over time in bodyweight in pigs. He feels that an increase in bodyweight of 0.2 kg per week above that observed in the study for which the data are provided would be important, and would like to design a study to have 90% power to detect this increase using a two-sided 0.05 level of significance.
#### a. What sample size would be needed in the randomized trial if the growth rate in the control group (without the additive) was the same as observed in the study for which the data are provided? Assume that the duration of the study from the first to last measurement is 8 weeks and that measurements are obtained every 4 weeks using the same technique as in the study for which the data are provided (so a measurement at times 0, 4 and 8 weeks). Also assume that equal numbers are randomized to each of the intervention (with the additive) and control groups and that the variance components observed in the study for which the data provided are reasonable choices for what would be found in the proposed trial. Show how you derived your answer.

Define:  
Effect size, $\delta =$ 0.2  
Power, $1 - \gamma =$ 0.9  
Significance, $\alpha =$ 0.05  
Within-subject time effect variance, $\sigma^2_{\epsilon} =$ `r round(weight.summary$varFix[2, 2], 3)`  
Between-subject time effect variance, $g_{22} =$ `r round(random.cov[2, 2], 3)`

```{r}
delta <- 0.2
power.g <- 0.9
alpha <- 0.05
tau <- 8
n <- 3
```


We can calculate the necessary group sample size with the formula:

$$
N = {{(Z_{1 - \alpha/2} + Z_{1 - \gamma})^2 \times 2\sigma^2}\over{\delta^2}}
$$

Where
$$
\sigma^2 = \sigma^2_{\epsilon}\left \{\sum_{j=1}^{n}(t_{j} - \bar{t})^2 \right \}^{-1} + g_{22}
$$

Because the measurements are taken at equally spaced times (specifically, four weeks), we can use this simplification (the length of the study, $\tau$ is `r tau` weeks):

```{r}
simplify <- (tau^2 * n * (n - 1))/(12 * (n - 1))
```

$$
\sum_{j=1}^{n}(t_{j} - \bar{t})^2 = {{\tau^2n(n - 1)}\over{12(n - 1)}} = {{`r tau^2` \times `r n` \times `r n - 1`}\over{12 \times `r n - 1`}} = `r simplify`
$$

Recalling the variance component for sample size calculation, $\sigma^2$ and substituting values from the simplification above:
$$
\sigma^2 = \sigma^2_{\epsilon}\left \{\sum_{j=1}^{n}(t_{j} - \bar{t})^2 \right \}^{-1} + g_{22} = {{\sigma^2_{\epsilon}}\over{16}} + g_{22}
$$

And using variance estimates from question 2, above, $\sigma^2_{\epsilon} =$ `r round(weight.summary$varFix[2, 2], 3)` and $g_{22} =$ `r round(random.cov[2, 2], 3)`:

```{r}
var.comp <- round(weight.summary$varFix[2, 2]/simplify + random.cov[2, 2], 3)
```


$$
\sigma^2 = {{`r round(weight.summary$varFix[2, 2], 3)`}\over{`r simplify`}} + `r round(random.cov[2, 2], 3)` = `r var.comp`
$$

Substituting this value of $\sigma^2$ into our formula for sample size, along with $\delta$:
$$
N = {{(Z_{1 - \alpha/2} + Z_{1 - \gamma})^2 \times 2\sigma^2}\over{\delta^2}} \\
= {{(Z_{1 - \alpha/2} + Z_{1 - \gamma})^2 \times 2 \times `r var.comp`^2}\over{`r delta`^2}}
$$

```{r}
# Get critical values for Z-statistics
z.alpha <- qnorm(p = (1 - alpha/2))
z.gamma <- qnorm(p = power.g)

# Calculate sample size
sample.size <- ( (z.alpha + z.gamma)^2 + var.comp^2 ) / delta^2
```

Finally, using the critical Z scores, $Z_{1 - \alpha/2} =$ `r round(z.alpha, 3)` and $Z_{1 - \gamma} =$ `r round(z.gamma, 3)`:
$$
N = {{(Z_{1 - \alpha/2} + Z_{1 - \gamma})^2 \times 2 \times `r var.comp`^2}\over{`r delta`^2}} \\
= {{(`r round(z.alpha, 3)` + `r round(z.gamma, 3)`)^2 \times 2 \times `r var.comp`^2}\over{`r delta`^2}} \\
= `r round(sample.size, 3)`
$$
So, in order to detect an effect size of `r delta`, the investigator would need `r round(sample.size, 0)` subjects in each group, or `r 2 * round(sample.size, 0)` total samples.

#### b. What do you notice about the data provided that could affect the sample size needed? Briefly justify your answer.

#### c. As the experimental additive is currently difficult to produce, the investigator is interested in knowing whether more frequent measurements or a longer study would markedly reduce the sample size. Develop a table which shows the sample size requirement if measurements were obtained every 4 weeks over an 8 week period (as done for part a), every 4 weeks over a 16 week period, every week over an 8 week period, or every week over a 16 week period. Briefly comment on any additional considerations that might be important in choosing among these four possible designs.

***
The R code used in this assignment can be found in a corresponding R Markdown document at [https://github.com/jcoliver/bios-684/blob/master/homework-6-oliver.Rmd](https://github.com/jcoliver/bios-684/blob/master/homework-6-oliver.Rmd).
