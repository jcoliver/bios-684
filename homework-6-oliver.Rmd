---
title: "Homework 6"
subtitle: "BIOS 684"
author: "Jeff Oliver"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
  latex_engine: xelatex
---

```{r setup, include=FALSE, fig.height = 4}
knitr::opts_chunk$set(echo = FALSE, dev = "pdf")
library("tidyr")
library("dplyr")
library("ggplot2")
library("nlme")
```

***
<!--
Study of weights of pigs:
The dataset (on the class web page) called pigweight.txt includes data on the bodyweights
of 16 pigs measured in nine successive weeks (so spanning an eight week period between
the first and last measurement). Each row of the dataset includes a pig ID number and
then the nine successive weights. [The data are from the book by Diggle et al., 2002].
-->

```{r}
pig.data <- read.delim(file = "data/pigweight.txt", header = FALSE, sep = " ")
colnames(pig.data) <- c("ID", paste0("week.", c(0:8)))
pig.data$ID <- factor(pig.data$ID)

long.data <- gather(data = pig.data, key = "week.cat", value = "weight", -ID)
long.data$week <- as.integer(substr(x = long.data$week.cat, start = 6, stop = 6))
```

### 1. Descriptive Analysis
### Create two plots, one showing the trajectories of each pigâ€™s weight over time and the other showing the trajectory of the mean weight over time. Comment on the notable features in these plots.

```{r}
# Plot individual trajectories
subject.trajectories <- ggplot(data = long.data, mapping = aes(x = week, y = weight, group = ID)) +
  geom_line() +
  ylab(label = "Weight") +
  xlab(label = "Week") +
  ggtitle(label = "Individual weight trajectories over time")
subject.trajectories

# Calculate means & standard errors for each week
mean.weights <- long.data %>%
  group_by(week) %>%
  summarise(mean.weight = mean(weight),
            se.weight = sd(weight)/sqrt(nrow(pig.data)))
# Plot mean trajectory
mean.trajectories <- ggplot(data = mean.weights, mapping = aes(x = week, y = mean.weight)) +
  geom_errorbar(data = mean.weights, mapping = aes(x = week, ymin = (mean.weight - se.weight), ymax = (mean.weight + se.weight), width = 0.15)) +
  geom_line() +
  ylab(label = "Weight") +
  xlab(label = "Week") +
  ggtitle(label = "Population mean weights over time")
mean.trajectories
```

Observations: All subjects have increasing weight through time, and the relationship appears linear for the time studied. There might be subject-specific intercepts and slopes, though; subjects that had low weight at baseline had potentially lower growth rates than did subjects with higher baseline weights. This potential difference in slopes may be contributing to increasing between-subject variance over time (heterogeneous variance). There appears to be little variation in slopes within subjects over time.

### 2. Obtaining and Interpreting a Linear Mixed Effects Model for Bodyweight. Using PROC MIXED, fit a model for weight over (continuous) time which includes subject-specific intercepts and slopes as random effects.

The model is:

$$
Y_{ij} = \beta_{1} + \beta_{2}Week + b_{1i} + b_{2i}Week + \varepsilon_{ij}
$$
Where:

+ $\beta_{1}$: the mean intercept across subjects
+ $\beta_{2}$: the mean slope across subjects
+ $b_{1i}$: random (subject-specific) effect on intercept
+ $b_{2i}$: random (subject-specific) effect on slope

```{r}
# lme model with random intercept and slope
weight.model <- lme(weight ~ week,
                    random = ~1 + week | ID,
                    data = long.data)
weight.summary <- summary(weight.model)
```

#### a. Obtain and interpret parameter estimates and associated 95% confidence intervals for the fixed effects in the model for the mean trajectory.

To obtain the 95% confidence intervals, I used: $95\% C.I. = \hat{\beta} \pm 1.96 \times SE$.

```{r}
# Retrieve estimates and standard errors for fixed effects
betas <- data.frame(estimate = weight.summary$tTable[, 1], se = weight.summary$tTable[, 2])

# Calculate 95% C.I.
ci <- matrix(nrow = 2, ncol = 2)
ci[1, ] <- c(betas[1, 1] + c(-1, 1) * 1.96 * betas[1, 2])
ci[2, ] <- c(betas[2, 1] + c(-1, 1) * 1.96 * betas[2, 2])

betas <- round(betas, 2)
ci <- round(ci, 2)
```

| Coefficient | Estimate (CI)     | Interpretation                                                  |
|:-----------:|:-----------------:|:----------------------------------------------------------------|
| $\beta_{1}$ | `r betas[1, 1]` (`r ci[1, 1]`, `r ci[1, 2]`)| The population-averaged weight at baseline is `r betas[1, 1]`; the 95% C.I. excludes zero, so it is unlikely the true population-averaged weight at baseline is zero. |
| $\beta_{2}$ | `r betas[2, 1]` (`r ci[2, 1]`, `r ci[2, 2]`)| The population-averaged effect of time on weight is `r betas[2, 1]`; on average, weight increases by `r betas[2, 1]` every week. Exclusion of zero from the confidence interval indicates a significant effect of time on weight. |

#### b. Obtain and interpret parameter estimates for the variances and correlation in the model.

$Var(\beta_{1}) =$ `r round(weight.summary$varFix[1, 1], 2)`  
$Var(\beta_{2}) =$ `r round(weight.summary$varFix[2, 2], 2)`  
$Corr(\beta_{1}, \beta_{2}) =$ `r round(weight.summary$corFixed[1, 2], 2)`  

$Var(\beta_{1})$ and $Var(\beta_{2})$ show relatively low variance in population-averages estimates of weight at baseline and the change in weight over time. The correlation, $Corr(\beta_{1}, \beta_{2})$, is negative, indicating that, on average, higher weight at baseline leads to lower weight gain through time.

#### c. Obtain and interpret the 90% normal range for trends over time in body weight among pigs in the population sampled (i.e. for the pig-specific random effects for trend over time).
```{r}
# Get random effects variance covariance matrix
random.cov <- getVarCov(obj = weight.model)

# Calculate standard deviation for random time effect
time.sd <- sqrt(random.cov[2, 2])

# Calculate 5% and 95% values from normal distribution
range <- qnorm(p = c(0.05, 0.95), mean = 0, sd = time.sd)
range <- round(range, 3)
```

Assume $b_{2} \sim N(0, \sigma^2_{b})$, where $\sigma^2_{b}$ is element $g_{22}$ in the G covariance matrix. In this example, $\sigma^2_{b} = g_{22} =$ `r round(random.cov[2, 2], 2)`. Using $N(0, `r round(random.cov[2, 2], 2)`)$, the 90% range of time effects among subjects is `r range[1]` to `r range[2]`. That is, 90% of the subjects should have a subject-specific per-week change in weight between `r range[1]` and `r range[2]` in addition to the population-average change in weight over time.

### 3. The investigator who provided the data is interested in designing a randomized clinical trial to evaluate an additive to the standard pig feed which might increase the rate of growth over time in bodyweight in pigs. He feels that an increase in bodyweight of 0.2 kg per week above that observed in the study for which the data are provided would be important, and would like to design a study to have 90% power to detect this increase using a two-sided 0.05 level of significance.
#### a. What sample size would be needed in the randomized trial if the growth rate in the control group (without the additive) was the same as observed in the study for which the data are provided? Assume that the duration of the study from the first to last measurement is 8 weeks and that measurements are obtained every 4 weeks using the same technique as in the study for which the data are provided (so a measurement at times 0, 4 and 8 weeks). Also assume that equal numbers are randomized to each of the intervention (with the additive) and control groups and that the variance components observed in the study for which the data provided are reasonable choices for what would be found in the proposed trial. Show how you derived your answer.

Define:  
Effect size, $\delta =$ 0.2  
Power, $1 - \gamma =$ 0.9  
Significance, $\alpha =$ 0.05  
Within-subject time effect variance, $\sigma^2_{\epsilon} =$ `r round(weight.summary$varFix[2, 2], 3)`  
Between-subject time effect variance, $g_{22} =$ `r round(random.cov[2, 2], 3)`

```{r}
delta <- 0.2
power.g <- 0.9
alpha <- 0.05
tau <- 8
n <- 3
```
_Note_: The answers and discussion that follow assume I have the correct value for within-subject time effect variance, $\sigma^2_{\epsilon} =$ `r round(weight.summary$varFix[2, 2], 3)`. I obtained this through the `varFix` element in the `summary.lme` object:

```{r echo = TRUE, eval = FALSE}
weight.model <- lme(weight ~ week,
                    random = ~1 + week | ID,
                    data = long.data)
weight.summary <- summary(weight.model)
within.var <- weight.summary$varFix[2, 2]
```

This concern is of most relevance to part (c), in considering sample size calculations for different repeated measures designs. I'm not entirely convinced I am using the right value, but for now I'll assume it is correct.

We can calculate the necessary group sample size with the formula:

$$
N = {{(Z_{1 - \alpha/2} + Z_{1 - \gamma})^2 \times 2\sigma^2}\over{\delta^2}}\tag{1}
$$

Where
$$
\sigma^2 = \sigma^2_{\epsilon}\left \{\sum_{j=1}^{n}(t_{j} - \bar{t})^2 \right \}^{-1} + g_{22}\tag{2}
$$

Because the measurements are taken at equally spaced times (specifically, four weeks), we can use this simplification (the length of the study, $\tau$ is `r tau` weeks):

```{r}
simplifyFunction <- function(tau, n) {
  return(((tau^2) * n * (n - 1))/(12 * (n - 1)))
}
simplify <- simplifyFunction(tau = tau, n = n)
```

$$
\sum_{j=1}^{n}(t_{j} - \bar{t})^2 = {{\tau^2n(n - 1)}\over{12(n - 1)}}\tag{3}
$$
Substituting in the values of duration ($\tau =$ `r tau`) and number of measurement points ($n =$ `r n`):

$$
\sum_{j=1}^{n}(t_{j} - \bar{t})^2 = {{`r tau^2` \times `r n` \times `r n - 1`}\over{12 \times `r n - 1`}} = `r simplify`
$$

Recalling the variance component for sample size calculation, $\sigma^2$, and substituting values from the simplification above into equation (2):
$$
\sigma^2 = \sigma^2_{\epsilon}\left \{\sum_{j=1}^{n}(t_{j} - \bar{t})^2 \right \}^{-1} + g_{22} = {{\sigma^2_{\epsilon}}\over{16}} + g_{22}
$$

And using variance estimates from question 2, above, $\sigma^2_{\epsilon} =$ `r round(weight.summary$varFix[2, 2], 3)` and $g_{22} =$ `r round(random.cov[2, 2], 3)`:

```{r}
var.comp <- weight.summary$varFix[2, 2]/simplify + random.cov[2, 2]
```


$$
\sigma^2 = {{`r round(weight.summary$varFix[2, 2], 3)`}\over{`r simplify`}} + `r round(random.cov[2, 2], 3)` = `r round(var.comp, 3)`
$$

Substituting this value of $\sigma^2$ into our formula for sample size, along with $\delta$:
$$
N = {{(Z_{1 - \alpha/2} + Z_{1 - \gamma})^2 \times 2\sigma^2}\over{\delta^2}} \\
= {{(Z_{1 - \alpha/2} + Z_{1 - \gamma})^2 \times 2 \times `r round(var.comp,2)`^2}\over{`r delta`^2}}
$$

```{r}
# Get critical values for Z-statistics
z.alpha <- qnorm(p = (1 - alpha/2))
z.gamma <- qnorm(p = power.g)

# Calculate sample size
sample.size <- ( (z.alpha + z.gamma)^2 * (2 * (var.comp^2)  ) ) / (delta^2)
```

Finally, using the critical Z scores, $Z_{1 - \alpha/2} =$ `r round(z.alpha, 3)` and $Z_{1 - \gamma} =$ `r round(z.gamma, 3)`:
$$
N = {{(Z_{1 - \alpha/2} + Z_{1 - \gamma})^2 \times 2 \times `r round(var.comp,2)`^2}\over{`r delta`^2}} \\
= {{(`r round(z.alpha, 3)` + `r round(z.gamma, 3)`)^2 \times 2 \times `r round(var.comp,2)`^2}\over{`r delta`^2}} \\
= `r round(sample.size, 3)`
$$
So, in order to detect an effect size of `r delta`, the investigator would need `r round(sample.size, 0)` subjects in each group, or `r 2 * round(sample.size, 0)` total samples.

#### b. What do you notice about the data provided that could affect the sample size needed? Briefly justify your answer.

Assuming the probability of Type I and Type II errors cannot be changed, there are two notable aspects of the experiment that have a significant effect on sample size. The first is the **effect size** the investigator is interested in detecting ($\delta =$ `r delta`). Given that the observed effect of time on weight (question 2) was `r betas[2, 1]`, the investigator wants to detect a fairly small effect, `r delta`/`r betas[2, 1]`. That is, the investigator wants to be able to detect an effect of the additive on growth rate even if it only changes the rate of weight gain by `r round(100 * delta/betas[2, 1], 2)`%. If the investigator is willing to test for a larger effect size, therefore increasing $\delta$ in equation (1), the resulting calculation will result in a smaller sample size (because $\delta$ is in the denominator).

Second, the **design of the repeated measures** only had a duration of `r tau` weeks and `r n` sampling points. If either of those could be increased, the necessary sample size to detect the desired effect size could be reduced. That is, as the magnitude of duration and the number of sampling points inversely affects the contribution of within-subjects variance ($\sigma^2_{\epsilon}$) in equation (2), increasing $\tau$ or $n$ will _decrease_ the influence of $\sigma^2_{\epsilon}$, and ultimately reduce the $2\sigma^2$ portion of equation (1) ($2\sigma^2$ is in the numerator). 

#### c. As the experimental additive is currently difficult to produce, the investigator is interested in knowing whether more frequent measurements or a longer study would markedly reduce the sample size. Develop a table which shows the sample size requirement if measurements were obtained every 4 weeks over an 8 week period (as done for part a), every 4 weeks over a 16 week period, every week over an 8 week period, or every week over a 16 week period. Briefly comment on any additional considerations that might be important in choosing among these four possible designs.

Potential sampling designs:

| Duration ($\tau$) | Interval (weeks) | Number of sampling points ($n$) |
|:-----------------:|:----------------:|:-------------------------------:|
| 8                 | 4                | `r round((8 / 4) + 1, 0)`       |
| 8                 | 1                | `r round((8 / 1) + 1, 0)`       |
| 16                | 4                | `r round((16 / 4) + 1, 0)`      |
| 16                | 1                | `r round((16 / 1) + 1, 0)`      |

```{r}
sigma.e <- weight.summary$varFix[2, 2]
g.22 <- random.cov[2, 2]
sum.z.scores <- z.alpha + z.gamma

sampleSize <- function(tau, n, sigma.e, g.22, delta, sum.z.scores) {
  simplify <- simplifyFunction(tau = tau, n = n)
  var.comp <- sigma.e/simplify + g.22
  sample.size <- ( (sum.z.scores^2) * (2 * var.comp^2) ) / (delta^2)
  return(sample.size)
}

designs <- data.frame(tau.values = c(8, 8, 16, 16),
                      n.values = c(3, 9, 5, 17),
                      sample.sizes = NA)

for (i in 1:nrow(designs)) {
  designs$sample.sizes[i] <- sampleSize(tau = designs$tau.values[i],
                                        n = designs$n.values[i],
                                        sigma.e = sigma.e,
                                        g.22 = g.22,
                                        delta = delta,
                                        sum.z.scores = sum.z.scores)
}

```

But substituting values into the simplification equation (3), the four possible designs will effect the sample size by weighting the within-subject variance component ($\sigma^2_{\varepsilon}$) by:

```{r design-1}
design <- 1
tau <- designs$tau.values[design]
n <- designs$n.values[design]
simplify <- simplifyFunction(tau = tau, n = n)
```
$\tau = `r tau`, \text{4 week intervals}, n = `r n`:$
$$
\sum_{j=1}^{n}(t_{j} - \bar{t})^2 = {{`r tau^2` \times `r n` \times `r n - 1`}\over{12 \times `r n - 1`}} = `r simplify`
$$
```{r design-2}
design <- 2
tau <- designs$tau.values[design]
n <- designs$n.values[design]
simplify <- simplifyFunction(tau = tau, n = n)
```
$\tau = `r tau`, \text{1 week intervals}, n = `r n`:$
$$
\sum_{j=1}^{n}(t_{j} - \bar{t})^2 = {{`r tau^2` \times `r n` \times `r n - 1`}\over{12 \times `r n - 1`}} = `r simplify`
$$

```{r design-3}
design <- 3
tau <- designs$tau.values[design]
n <- designs$n.values[design]
simplify <- simplifyFunction(tau = tau, n = n)
```
$\tau = `r tau`, \text{4 week intervals}, n = `r n`:$
$$
\sum_{j=1}^{n}(t_{j} - \bar{t})^2 = {{`r tau^2` \times `r n` \times `r n - 1`}\over{12 \times `r n - 1`}} = `r round(simplify, 2)`
$$

```{r design-4}
design <- 4
tau <- designs$tau.values[design]
n <- designs$n.values[design]
simplify <- simplifyFunction(tau = tau, n = n)
```
$\tau = `r tau`, \text{1 week intervals}, n = `r n`:$
$$
\sum_{j=1}^{n}(t_{j} - \bar{t})^2 = {{`r tau^2` \times `r n` \times `r n - 1`}\over{12 \times `r n - 1`}} = `r round(simplify, 2)`
$$
Using those values for scaling within-subject variance component in equation (2), and using those values for calculating sample size in equation (1), the designs would require the following sample sizes:

| Duration  | 4 week | 1 week |
|:----------|:------:|:------:|
| 8 weeks   | `r round(designs$sample.sizes[1], 0)` | `r round(designs$sample.sizes[2], 0)` |
| 16 weeks  | `r round(designs$sample.sizes[3], 0)` | `r round(designs$sample.sizes[4], 0)` |
_Note_: These are per-group sample sizes. Given two groups, control and treatment, the total sample size of the experiments would need to be double these values.

Assuming the value I used for within-subject variance ($\sigma^2_{\varepsilon}$) is correct (`r round(sigma.e, 3)`), changing the repeated measures design at the suggested scales would have relatively little influence on sample size. This is largely due to the difference in magnitude between within-subject variance ($\sigma^2_{\varepsilon} =$ `r round(sigma.e, 3)`) and between-subject variance ($g_{22} =$ `r round(g.22, 3)`). Because these components are added together in equation (2), and increasing duration or sample frequency only serves to _reduce_ the within-subject variance contribution to $\sigma^2$ of equation (1), the variance estimates $\sigma^2_{\varepsilon}$ and $g_{22}$ suggest alterations in the repeated measures design would have little influence on sample size. Indeed, even if within-subject variance ($\sigma^2_{\varepsilon}$) was zero, the required sample size would still be `r round(sampleSize(tau = 16, n = 17, sigma.e = 0, g.22 = g.22, delta = delta, sum.z.scores = sum.z.scores), 0)`, given a duration of 16 weeks with weekly sampling.

Considering a larger effect size might be another way to reduce the sample size. If investigators were willing to test for an effect size of 0.4 kg, it would afford a sample size of only `r round(sampleSize(tau = 8, n = 3, sigma.e = sigma.e, g.22 = g.22, delta = (delta * 2), sum.z.scores = sum.z.scores), 0)` for an experiment of 8 weeks, sampling at 4 week intervals.

***
The R code used in this assignment can be found in a corresponding R Markdown document at [https://github.com/jcoliver/bios-684/blob/master/homework-6-oliver.Rmd](https://github.com/jcoliver/bios-684/blob/master/homework-6-oliver.Rmd).
