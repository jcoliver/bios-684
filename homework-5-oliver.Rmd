---
title: "Homework 5"
subtitle: "BIOS 684"
author: "Jeff Oliver"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
  latex_engine: xelatex
---

```{r setup, include=FALSE, fig.height = 4}
knitr::opts_chunk$set(echo = FALSE, dev = "pdf")
library("ggplot2")
library("tidyr")
library("dplyr")
library("nlme")
```

<!--
To review concepts of linear mixed effects models
Instructions:
1) For each question requiring data analysis, support your conclusions by including only the relevant SAS output in your answer.
2) Include your SAS program as an appendix to your solutions.

Analysis of Data from Dental Growth Study
In a study of dental growth, measurements of the distance (mm) from the center of the pituitary gland to the pteryomaxillary fissure were obtained on 11 girls and 16 boys at ages 8, 10, 12 and 14 years (Potthoff and Roy, 1964). The data are in the file “dental.txt” on the course web page. Each row of the data set contains the following six variables: subject ID, gender (“F” or “M”), and the measurements at ages 8, 10, 12 and 14 years, respectively.

Note that in HW2 was based on this study, but you analyzed data only from the girls. In this homework please analyze ALL the data.
-->

```{r data}
# Read in data
dental.data <- read.csv(file = "data/dental.csv", header = FALSE)

# Sampling vector for later use
years <- c(8, 10, 12, 14)
years.chr <- c("08", "10", "12", "14")

# Add column names
colnames(dental.data) <- c("ID", "gender", paste0("y.", years.chr))

# Create a long version, too
dental.long <- gather(data = dental.data,
                      key = "year.cat",
                      value = "distance",
                      -gender, -ID)

# Make a continuous year column
dental.long$year <- as.numeric(gsub(pattern = "y.", replacement = "", x = dental.long$year.cat))

# Make sure we have a categorical year
dental.long$year.cat <- as.factor(dental.long$year)
```

### 1. Descriptive Analysis
#### a. Describe key features of the study’s design and the completeness of data.

The study has a total of `r nrow(dental.data)` subjects, `r sum(dental.data$gender == "F")` girls and `r sum(dental.data$gender == "M")` boys. All subjects were sampled at each of four time points (8, 10, 12, and 14 years), thus the experimental design is balanced and the data are complete.

#### b. Create two plots, one for each gender, showing the trajectories of each subject’s distance over time. Comment on the notable features in these trajectories.
```{r spaghetti-plot}
trajectories <- ggplot(data = dental.long, mapping = aes(x = year, y = distance, group = ID)) +
  geom_line() + 
  facet_grid(~ gender)

trajectories
```

#### c. Create a single plot of the distance over time for each gender. Comment on the notable features in this plot.
```{r group-means}
# Calculate means and standard deviation for each sampling point and each gender
dental.means <- dental.long %>%
  group_by(gender, year.cat) %>%
  summarize(mean.distance = mean(distance),
            sd.distance = sd(distance))

# Calculate standard errors for the two groups
dental.means$se.distance <- NA
dental.means$se.distance[dental.means$gender == "F"] <- dental.means$sd.distance[dental.means$gender == "F"] / sqrt(sum(dental.data$gender == "F"))
dental.means$se.distance[dental.means$gender == "M"] <- dental.means$sd.distance[dental.means$gender == "M"] / sqrt(sum(dental.data$gender == "M"))

# Plot the means
group.trajectories <- ggplot(data = dental.means, mapping = aes(x = year.cat, y = mean.distance, color = gender, group = gender)) +
  geom_point() + 
  geom_line() +
  geom_errorbar(data = dental.means, mapping = aes(x = year.cat, ymin = (mean.distance - se.distance), ymax = (mean.distance + se.distance)), width = 0.2) +
  scale_color_manual(name = "Gender", values = c("cadetblue", "darkred"), labels = c("F" = "Female", "M" = "Male")) +
  ylab(label = "Distance (mm)") + 
  xlab(label = "Year")

group.trajectories
```
  
In this plot of the means for each gender, both female and male subjects show an increase of distance over time. There appears, if 8 years is considered the baseline for this experiment, to be a different intercept between the two groups. That is, at the age of eight, males appear to have a larger distance than females at the same age. The rate of change between the two groups might be different, with a slightly higher rate of growth in males, but it is difficult to tell from this graph. There do not appear to be distinct differences in variance through time or between groups.

### 2. Two-Stage Analysis
#### First Stage: Using PROC REG (or PROC GLM), obtain estimates of the intercept and slope from the linear regression of distance on (continuous) age for each subject separately. Note: you do not need to provide the SAS output for each subject (this can be suppressed in your SAS code by using the NOPRINT option).
##### i) State the model being fitted for each subject including any distributional assumptions.

Our model for the distance measurement of the _i^th^_ subject is:

$$
Y_{i} = \beta_{1i} + \beta_{2i}t_{ij} + \varepsilon_{i}
$$
Where $\beta_{1i}$ is the intercept of the _i^th^_ subject, $\beta_{2i}$ is the slope describing the relationship between time and distance, and the within-subject error is normally distributed, $\varepsilon_{i}\sim N(0, \sigma_{i}^2)$. We are also assuming a linear relationship between time and distance and independence among the individual $\varepsilon_{i}$s.

##### ii) Calculate the means of the estimated intercepts and the estimated slopes for each of the two genders.
```{r stage-one-lmm}
# Identify subjects
ids <- unique(dental.long$ID)

# Set up data frame for intercepts and slopes
ind.betas <- data.frame(intercept = rep(x = NA, times = length(ids)),
                    slope = NA,
                    gender = NA)
rownames(ind.betas) <- ids
ind.betas$gender <- factor(NA, levels = levels(dental.long$gender))

# Iterate over each ID and estimate model coefficients
for (id in ids) {
  current.data <- dental.long[dental.long$ID == id, ]
  current.lm <- lm(distance ~ year, data = current.data)
  ind.betas[id, "intercept"] <- current.lm$coefficients[[1]]
  ind.betas[id, "slope"] <- current.lm$coefficients[[2]]
  ind.betas[id, "gender"] <- current.data$gender[1]
}

# Calculate means for each gender
ind.beta.means <- ind.betas %>%
  group_by(gender) %>%
  summarize(mean.intercept = round(mean(intercept), 3),
            mean.slope = round(mean(slope), 3))
ind.beta.means <- data.frame(ind.beta.means)
rownames(ind.beta.means) <- ind.beta.means$gender
```
The mean values for intercept and slope are:

| Gender | Intercept | Slope |
|:-------|:---------:|:-----:|
| Female | `r ind.beta.means["F", "mean.intercept"]` | `r ind.beta.means["F", "mean.slope"]` |
| Male   | `r ind.beta.means["M", "mean.intercept"]` | `r ind.beta.means["M", "mean.slope"]` |

Note the intercept is for year 0, not year 8.

#### Second Stage:
##### i) Using the intercepts obtained in question 2a as the outcome variable, fit a regression model to compare the mean intercepts for each gender. State the model being fitted including any distributional assumptions (for terms in the model which are also parts of the model in question 2a, use the same notation). Obtain an estimate for the difference in mean intercept between genders together with the standard error for the difference. What do you conclude about the difference in mean intercept?
Our model for the mean intercepts of the two genders is:
$$
\beta_{1i} = \beta_{1} + \beta_{2}Gender_{i} + b_{1i}
$$
Where $\beta_{1}$ is the population-averaged intercept for girls (the first level of $Gender$), $\beta_{2}$ is the population-averaged difference between the intercepts of girls and boys, and $b_{1i}$ is the subject-specific measurement error in intercept, with a normal distribution $b_{1i} \sim N(0, Var(b_{1i}))$.

```{r stage-two-lmm-intercepts}
intercept.model <- lm(intercept ~ gender, data = ind.betas)
intercept.model.summary <- summary(intercept.model)
intercept.difference <- intercept.model.summary$coefficients[2, 1]
intercept.se <- intercept.model.summary$coefficients[2, 2]
int.diff.dir <- "lower"
if (intercept.difference > 0) {
  int.diff.dir <- "higher"
}
```

From this model, we estimate that the intercept in boys, on average, is `r int.diff.dir` than that of girls by `r abs(round(intercept.difference, 3))`. Given the standard error for this estimate (`r round(intercept.se, 3)`), it is unlikely the intercepts at age zero are different between the two genders. Note we would most likely have a different conclusion (intercepts _are_ different between boys and girls) if we had considered the intercept to be at year 8.

##### ii) Repeat i) but using the slopes obtained in question 2a as the outcome variable. What do you conclude about the difference in mean slope?

Our model for the mean slopes of the two genders is:
$$
\beta_{2i} = \beta_{3} + \beta_{4}Gender_{i} + b_{2i}
$$
Where $\beta_{3}$ is the population-averaged slope for girls (the first level of $Gender$), $\beta_{4}$ is the population-averaged difference between the slopes of girls and boys, and $b_{2i}$ is the subject-specific measurement error in slope, with a normal distribution $b_{2i} \sim N(0, Var(b_{2i}))$.

```{r stage-two-lmm-slopes}
slope.model <- lm(slope ~ gender, data = ind.betas)
slope.model.summary <- summary(slope.model)
slope.difference <- slope.model.summary$coefficients[2, 1]
slope.se <- slope.model.summary$coefficients[2, 2]
slope.diff.dir <- "lower"
if (slope.difference > 0) {
  slope.diff.dir <- "higher"
}
```

From this model, we estimate that the slope in boys, on average, is `r slope.diff.dir` than that of girls by `r abs(round(slope.difference, 3))`. Given the standard error for this estimate (`r round(slope.se, 3)`), it is likely the slopes are different between the two genders.

##### iii) Obtain and interpret the standard deviation of the residuals (“errors”) from the model in part ii).
```{r residuals}
slope.residual.sd <- round(sd(slope.model.summary$residuals), 3)
slope.residual.var <- round(sd(slope.model.summary$residuals)^2, 3)
```
The standard deviation of the residuals is `r slope.residual.sd`. This is the standard deviation for, $b_{2i}$, the individual deviations from the population-averaged slope. Taking the square of this standard deviation then gives $\sigma^2 = Var(b_{2i}) = `r slope.residual.var`$.

### (Joint) Mixed Effects Analysis. 
#### Using PROC MIXED, fit a model for distance on (continuous) age which includes subject-specific intercepts and slopes as random effects and allows both the mean intercept and the mean slope (fixed effects) to differ by gender.
```{r lmm-model}
lmm <- lme(fixed = distance ~ gender + year + gender * year,
           random = ~1 + year | ID,
           data = dental.long)
```

#### a. State the model being fitted including any distributional assumptions. As much as possible, use the same notation as you used in question 2.

Our model for distance is:
$$
Y_{ij} = \beta_{1} + \beta_{2}Gender_{i} + \beta_{3}t_{ij} + \beta_{4}Gender_{i} \times t_{ij} + b_{1i} + b_{2i}t_{ij} + \varepsilon_{ij}
$$

Where:

+ $\beta_{1}$ is the population-averaged intercept at age 0 for girls
+ $\beta_{2}$ is the population-averaged difference in intercepts at age 0 between girls and boys
+ $\beta_{3}$ is the population averaged slope for girls
+ $\beta_{4}$ is the population-averaged difference in slope between girls and boys
+ $b_{1i}$ is the random effect intercept for the _i^th^_ subject
+ $b_{2i}$ is the random effect slope for the _i^th^_ subject

The random effects, $b_{i} \sim MVN(0, G)$, where $G$ is a $2 \times 2$ matrix:

$$
G = 
\begin{pmatrix}
g_{11} & g_{12} \\
g_{21} & g_{22}
\end{pmatrix}
$$
and $g_{11} = Var(b_{1i})$, $g_{22} = Var(b_{2i})$, and $g_{12} = g_{21} = Cov(b_{1i}, b_{2i})$. Finally, we are assuming conditional independence, where the within-subject error is $\varepsilon_{ij} \sim N(0, R_{i})$ and $R_{i} = \sigma^2I_{n_{i}}$.

#### b. Compare the within-subject “error” variance to the between subject variance of the intercepts. What do you conclude?
```{r within-between-error}
# Within-subject variance
within.var <- lmm$sigma^2

# Between subject variance
g.matrix <- getVarCov(obj = lmm)
between.var.intercept <- g.matrix[1, 1]
```

The within-subject variance is `r round(within.var, 3)`, while the between-subject variance in intercepts is `r round(between.var.intercept, 3)`. The greater between-subject variance suggests (to me, at least), that the fixed effects have a greater impact on intercept than does within-subject variation (random effects).

#### c. Obtain estimates for the differences in mean intercept and mean slope by gender and their associated standard errors. What do you conclude about these differences?
```{r gender-differences-lmm}
lmm.summary <- summary(object = lmm)
betas <- data.frame(coeff = c("intercept", "group", "slope", "interaction"), estimate = NA, se = NA)
betas[, 2:3] <- lmm.summary$tTable[, 1:2]
rownames(betas) <- betas$coeff

reporting <- c("lower", "lower")

names(reporting) <- c("group", "interaction")
if (betas["group", "estimate"] > 0) {
  reporting["group"] <- "higher"
}
if (betas["interaction", "estimate"] > 0) {
  reporting["interaction"] <- "higher"
}


group.ci <- c(betas["group", "estimate"] - 1.96*betas["group", "se"], betas["group", "estimate"] + 1.96*betas["group", "se"])
group.ci <- round(group.ci, 3)
interaction.ci <- c(betas["interaction", "estimate"] - 1.96*betas["interaction", "se"], betas["interaction", "estimate"] + 1.96*betas["interaction", "se"])
interaction.ci <- round(interaction.ci, 3)
```

**Intercept:** The expected intercept at age 0 for boys is `r reporting["group"]` than girls by `r abs(round(betas["group", "estimate"], 3))` mm. The 95% CI is (`r group.ci[1]`, `r group.ci[2]`); as zero is included in this interval, it is unlikely that the intercept at age 0 is different between girls and boys.

**Slope:** The expected slope for boys is `r reporting["interaction"]` than girls by `r abs(round(betas["interaction", "estimate"], 3))` mm/year. The 95% CI is (`r interaction.ci[1]`, `r interaction.ci[2]`); this interaction does not include zero, suggesting that the population-averaged slopes of girls and boys are different.

#### d. Compare the estimates and their standard errors in question 3c to those obtained in question 2. What do you notice? Will this occur in all randomized trials with two groups and longitudinal measurements? Justify your answer.
```{r compare-estimates}
# Extract parameter estimates from relevant models for reporting
beta.compare <- data.frame(two.stage.est = rep(NA, times = 4), 
                           two.stage.se = NA,
                           lmm.est = NA,
                           lmm.se = NA)
rownames(beta.compare) <- c("Intercept", "Gender", "Slope", "Interaction")

beta.compare["Intercept", ] <- c(intercept.model.summary$coefficients[1, 1:2], lmm.summary$tTable[1, 1:2])
beta.compare["Gender", ] <- c(intercept.model.summary$coefficients[2, 1:2], lmm.summary$tTable[2, 1:2])
beta.compare["Slope", ] <- c(slope.model.summary$coefficients[1, 1:2], lmm.summary$tTable[3, 1:2])
beta.compare["Interaction", ] <- c(slope.model.summary$coefficients[2, 1:2], lmm.summary$tTable[4, 1:2])
beta.compare <- round(beta.compare, 3)
```

The estimates for the coefficients (with standard errors) are:

| Coefficient | 2-Stage (question 2) | LMM (question 3c) |
|:------------|:--------------------:|:-----------------:|
| Intercept   | `r beta.compare[1, 1]` (`r beta.compare[1, 2]`) | `r beta.compare[1, 3]` (`r beta.compare[1, 4]`) |
| Gender      | `r beta.compare[2, 1]` (`r beta.compare[2, 2]`) | `r beta.compare[2, 3]` (`r beta.compare[2, 4]`) |
| Slope       | `r beta.compare[3, 1]` (`r beta.compare[3, 2]`) | `r beta.compare[3, 3]` (`r beta.compare[3, 4]`) |
| Interaction | `r beta.compare[4, 1]` (`r beta.compare[4, 2]`) | `r beta.compare[4, 3]` (`r beta.compare[4, 4]`) |

These estimates are identical between the two approaches. The similarity in estimates is likely due to our balanced design - all subjects were measured at the same four time points. If the number and/or timing of measurements varies among subjects, these estimates would not likely be the same, due to the fact that the $\beta_{i}$ coefficents are estimated in stage I is not accounted for in stage II. Additionally, the two-stage approach restricts all covariates in stage I to be time-variant (except for the intercept), while stage II covariates must be time-invariant (gender, group, etc.). The linear mixed effects model only requires the random-effects covariates be a subset of the fixed-effects covariates.

#### e. Obtain and provide an interpretation for the correlation of the intercept and slope among subjects.
The correlation between intercept and slope between subjects is $Cov(b_{1i}, b_{2i}) = `r round(g.matrix[1, 2], 3)`$, indicating that subjects with larger intercepts have lower slopes and vice-versa.

#### f. From your model, conditional upon gender, obtain the standard deviation of the slopes among subjects. Provide a clinically meaningful interpretation of this standard deviation.
The standard deviation of slopes among girls is $Var(b_{2i}) = `r round(sqrt(g.matrix[2, 2]), 3)`$. This is a measure of the variation in the effect of time on distance in girls.

#### g. Obtain the marginal correlation matrix for the vector of responses, $Y_{i} = (Y_{i1}, Y_{i2}, Y_{i3}, Y_{i4})$, for the subject with ID=1. Considering your findings in response to question 3b, why are the correlations relatively large but not extremely strong?
```{r marginal-correlation-1}
subj.1.var <- getVarCov(obj = lmm, individuals = 1, type = "marginal")
corr.matrix <- cov2cor(as.matrix(subj.1.var[[1]]))
corr.matrix <- round(corr.matrix, 3)
```

The correlation matrix is:
$$
\begin{bmatrix}
`r corr.matrix[1, 1]` & `r corr.matrix[1, 2]` & `r corr.matrix[1, 3]` & `r corr.matrix[1, 4]` \\
`r corr.matrix[2, 1]` & `r corr.matrix[2, 2]` & `r corr.matrix[2, 3]` & `r corr.matrix[2, 4]` \\
`r corr.matrix[3, 1]` & `r corr.matrix[3, 2]` & `r corr.matrix[3, 3]` & `r corr.matrix[3, 4]` \\
`r corr.matrix[4, 1]` & `r corr.matrix[4, 2]` & `r corr.matrix[4, 3]` & `r corr.matrix[4, 4]`
\end{bmatrix}
$$
Given the relatively low within-subject variation observed in question 3b, the weak correlations are expected; the fixed-effects of time and gender have a substantial influence of the response profile of distance.

#### h. The data for this study could also be analyzed using the repeated measures approach discussed extensively earlier in the course.
##### i) Define a repeated measures model with an unstructured variance- covariance matrix and the same form of fixed effects model as in question 3a which could be used.

$$
Y_{ij} = \beta_{1} + \beta_{2}Gender_{i} + \beta_{3}X_{1ij} + \beta_{4}X_{2ij} + \beta_{5}X_{3ij} + \beta_{6}Gender_{i} \times X_{1ij} + \beta_{7}Gender_{i} \times X_{2ij} + \beta_{8}Gender_{i} \times X_{3ij} + \varepsilon_{ij}
$$
Where:
$$
\begin{array}{l}
  Gender_{i} =  
    \begin{cases}
      0, & \text{if subject is a girl} \\
      1, & \text{if subject is a boy}
    \end{cases} \\
  X_{1ij} = 1 \text{ if measurement is for year 10, 0 otherwise} \\
  X_{2ij} = 1 \text{ if measurement is for year 12, 0 otherwise} \\
  X_{3ij} = 1 \text{ if measurement is for year 14, 0 otherwise}
\end{array}
$$

With an unstructured covariance for $Y_{ij}$:
$$
Cov(Y_{i}) = 
\begin{pmatrix}
\sigma_{8}^2 & \sigma_{8, 10} & \sigma_{8, 12} & \sigma_{8, 14} \\
\sigma_{10,8} & \sigma_{10}^2 & \sigma_{10, 12} & \sigma_{10, 14} \\
\sigma_{12,8} & \sigma_{12, 10} & \sigma_{12}^2 & \sigma_{12, 14} \\
\sigma_{14,8} & \sigma_{14, 10} & \sigma_{14, 12} & \sigma_{14}^2
\end{pmatrix}
$$
This unstructured variance-covariance model requires 10 variance parameters to be estimated.

##### ii) Fit this model and use the AIC statistic to assess the goodness of fit of the variance-covariance structure induced by the mixed effects model. What do you conclude?
```{r repeated-anova}
repeated.anova <- gls(distance ~ year,
                      data = dental.long,
                      correlation = corSymm(form = ~1 | ID),
                      weights = varIdent(form = ~1 | year.cat),
                      method = "REML")
repeated.summary <- summary(repeated.anova)

```
The AIC for this repeated-measures ANOVA is `r round(repeated.summary$AIC, 3)`, which is higher than the AIC for the linear mixed effects model (`r round(lmm.summary$AIC, 3)`). Thus the linear mixed effects model is preferred given the lower AIC. The difference likely stems from the fact that the repeated-measures ANOVA design requires more parameters to be estimated for the model than does the linear mixed-effects model.

***
***
The R code used in this assignment can be found in a corresponding R Markdown document at [https://github.com/jcoliver/bios-684/blob/master/homework-5-oliver.Rmd](https://github.com/jcoliver/bios-684/blob/master/homework-5-oliver.Rmd).
